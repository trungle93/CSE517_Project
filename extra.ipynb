{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# follow the instructions in README to perform prompt tuning and probe predictivity of neurons\n",
    "# model-type argument default has already been changed to BertPrompt\n",
    "# we'll have an output file at example/sst2/test_perf containing predictivity of all neurons\n",
    "\n",
    "test_perf = torch.load('example/sst2/test_perf')\n",
    "print('test_perf', type(test_perf), test_perf.shape, test_perf[0,0])\n",
    "pred = np.max(test_perf, axis=1).flatten()\n",
    "print('pred', pred.shape)\n",
    "print('max pred', pred.max())\n",
    "plt.figure()\n",
    "plt.hist(pred, bins=20, range=(0,1))\n",
    "plt.xlabel('predictivity')\n",
    "plt.ylabel('number of neurons')\n",
    "plt.title('histogram of neuron\\'s predictivity for SST2')\n",
    "\n",
    "test_perf = torch.load('example_bert_imdb/imdb/test_perf')\n",
    "print('test_perf', type(test_perf), test_perf.shape, test_perf[0,0])\n",
    "pred = np.max(test_perf, axis=1).flatten()\n",
    "print('pred', pred.shape)\n",
    "print('max pred', pred.max())\n",
    "plt.figure()\n",
    "plt.hist(pred, bins=20, range=(0,1))\n",
    "plt.xlabel('predictivity')\n",
    "plt.ylabel('number of neurons')\n",
    "plt.title('histogram of neuron\\'s predictivity for IMDB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# perturb top skill neurons:\n",
    "\n",
    "mask_perf_mean_list = []\n",
    "cmp_perf_mean_list = []\n",
    "mask_perf_var_list = []\n",
    "cmp_perf_var_list = []\n",
    "for percentage in np.arange(0.0, 0.2, step=0.01):\n",
    "    temp_mask_avg = []\n",
    "    temp_cmp_avg = []\n",
    "    for _ in np.arange(5):\n",
    "        path = f'example/info/sst2/{percentage}'\n",
    "        !python src/mask.py --info_path $path --resume_from example --data_path data/raw/sst2 --save_to example --bz 16 -p  --cmp\n",
    "        mask_perf = torch.load('example/mask_perf')\n",
    "        cmp_perf = torch.load('example/cmp_perf')\n",
    "        temp_mask_avg.append(mask_perf['acc'])\n",
    "        temp_cmp_avg.append(cmp_perf['acc'])\n",
    "        print('mask_perf', type(mask_perf), mask_perf['acc'])\n",
    "        print('cmp_perf', type(cmp_perf), cmp_perf['acc'])\n",
    "    mask_perf_mean_list.append(np.mean(temp_mask_avg))\n",
    "    cmp_perf_mean_list.append(np.mean(temp_cmp_avg))\n",
    "    mask_perf_var_list.append(np.var(temp_mask_avg))\n",
    "    cmp_perf_var_list.append(np.var(temp_cmp_avg))\n",
    "print('mask_perf_mean_list', len(mask_perf_mean_list), mask_perf_mean_list)\n",
    "print('cmp_perf_mean_list', len(cmp_perf_mean_list), cmp_perf_mean_list)\n",
    "print('mask_perf_var_list', len(mask_perf_var_list), mask_perf_var_list)\n",
    "print('cmp_perf_var_list', len(cmp_perf_var_list), cmp_perf_var_list)\n",
    "np.save('bert_mask_perf_mean.npy', mask_perf_mean_list)\n",
    "np.save('bert_cmp_perf_mean.npy', cmp_perf_mean_list)\n",
    "np.save('bert_mask_perf_var.npy', mask_perf_var_list)\n",
    "np.save('bert_cmp_perf_var.npy', cmp_perf_var_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('skill-neuron')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9ae756d3afc2001b0408ca4dcff1d38cfb6c0261b84108fe443637ea45f582e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
